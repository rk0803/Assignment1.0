{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 1.ipynb","provenance":[{"file_id":"1LAstKrBnscHn76svnP7FNOYgRvR7qkw4","timestamp":1620035417912}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"GC_6PeobwwkH"},"source":["import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","torch.manual_seed(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bL64bMTkw2GP","executionInfo":{"status":"ok","timestamp":1620187339956,"user_tz":-330,"elapsed":1060,"user":{"displayName":"Ritambhra Korpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVTs8WqR_O80rsXO6tVh5uGAtlP3cdOy0OgQoq-g=s64","userId":"16099834797387286691"}}},"source":["X = torch.Tensor([[0,0], [0,1], [1,0], [1,1]])\n","Y = torch.Tensor([0, 1, 1, 0]).view(-1,1)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"aC82kEAIw3Wf","executionInfo":{"status":"ok","timestamp":1620187503160,"user_tz":-330,"elapsed":979,"user":{"displayName":"Ritambhra Korpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVTs8WqR_O80rsXO6tVh5uGAtlP3cdOy0OgQoq-g=s64","userId":"16099834797387286691"}}},"source":["class XOR(nn.Module):\n","    def __init__(self, input_dim = 2, output_dim=1):\n","        super(XOR, self).__init__()\n","        self.lin1 = nn.Linear(input_dim, 5)\n","        self.lin2=nn.Linear(5,4)\n","        #self.lin3=nn.Linear(5,4)\n","        self.lin3 = nn.Linear(4, output_dim)\n","    \n","    def forward(self, x):\n","        x = self.lin1(x)\n","        x = torch.tanh(x)\n","        x = self.lin2(x)\n","        x = torch.tanh(x)\n","        x = self.lin3(x)\n","        return x"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WKGdLXKRuY78"},"source":["F.tanh is changed to torch.tanh as it was giving a warning that torch.nn.functional (F here) is deprecated, use torch.tanh instead"]},{"cell_type":"code","metadata":{"id":"8gQIQExYw65K"},"source":["model = XOR()\n","print(model)\n","from torchsummary import summary\n","summary(model, (2,2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeotEq19x6XF","executionInfo":{"status":"ok","timestamp":1620187609867,"user_tz":-330,"elapsed":920,"user":{"displayName":"Ritambhra Korpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVTs8WqR_O80rsXO6tVh5uGAtlP3cdOy0OgQoq-g=s64","userId":"16099834797387286691"}}},"source":["def weights_init(model):\n","    for m in model.modules():\n","        if isinstance(m, nn.Linear):\n","            # initialize the weight tensor, here we use a normal distribution\n","            m.weight.data.normal_(0, 1)\n","\n","weights_init(model)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrD_sNzLx78e","executionInfo":{"status":"ok","timestamp":1620187613534,"user_tz":-330,"elapsed":1115,"user":{"displayName":"Ritambhra Korpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVTs8WqR_O80rsXO6tVh5uGAtlP3cdOy0OgQoq-g=s64","userId":"16099834797387286691"}}},"source":["loss_func = nn.L1Loss()"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zvbrMd2x_lA","executionInfo":{"status":"ok","timestamp":1620187615403,"user_tz":-330,"elapsed":998,"user":{"displayName":"Ritambhra Korpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgVTs8WqR_O80rsXO6tVh5uGAtlP3cdOy0OgQoq-g=s64","userId":"16099834797387286691"}}},"source":["optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"q7tWa3D7yA5X"},"source":["epochs = 2001\n","steps = X.size(0)\n","for i in range(epochs):\n","    for j in range(steps):\n","        data_point = np.random.randint(X.size(0))\n","        x_var = Variable(X[data_point], requires_grad=False)\n","        y_var = Variable(Y[data_point], requires_grad=False)\n","        \n","        optimizer.zero_grad()\n","        y_hat = model(x_var)\n","        loss = loss_func.forward(y_hat, y_var)\n","        loss.backward()\n","        optimizer.step()\n","        \n","    if i % 50 == 0:\n","        print( \"Epoch: {0}, Loss: {1}, \".format(i, loss.data.numpy()))\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mXtkUX6atX4g"},"source":["I tried with various learning rates (0.02( as given), and 0.002, 0.001) In the all the case the loss is going down, up, down and up again. till at last epoch it (sort of) settles down 0.00015646219. The fluctuation perhaps would have continued if I went on with more epochs, before reaching the actual minimum value (if its not overshot depending on the learning rate)\n"]},{"cell_type":"code","metadata":{"id":"QV0dIdveyCRi"},"source":[""],"execution_count":null,"outputs":[]}]}